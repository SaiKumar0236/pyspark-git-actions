 name: Submit PySpark Job to Dataproc

 on:
  push:
    branches: [ main ]

 permissions:
  id-token: write
  contents: read
 jobs:
  run-dataproc-job:
    runs-on: ubuntu-latest
 steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Authenticate to GCP
      uses: google-github-actions/auth@v2
      with:
        workload_identity_provider: ${{ secrets.WORKLOAD_IDENTITY_PROVIDER }}
        service_account: ${{ secrets.SERVICE_ACCOUNT_EMAIL }}


    - name: Upload PySpark file to GCS
      run: |
        gsutil cp pyspark/script.py gs://my-dataproc-scripts-bucket/scripts/
